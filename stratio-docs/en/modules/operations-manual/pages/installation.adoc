= Installation

== Prerequisites

=== EKS

* Roles and policies
+
For automated provisioning in EKS, actions must be performed across multiple services such as EC2, ECR, EKS, Elastic Load Balancing (ELB), etc. Although the use of these actions may vary depending on the installation type, the provider checks that the specified user has the required permissions to ensure correct operation.
+
** xref:attachment$stratio-eks-policy.json[Download permanent permissions for EKS].
** xref:attachment$stratio-aws-temp-policy.json[Download temporary permissions for EKS].
+
To deploy EKS, you must manually create the "AWSServiceRoleForAmazonEKS" role and attach the "AmazonEKSServiceRolePolicy" (created by default in AWS).

* Certified operating systems
+
To ensure compatibility between the _worker_ nodes and the EKS-managed _control-plane_, properly configured OS images must be used. It is recommended to generate these images using the https://github.com/kubernetes-sigs/image-builder[Kubernetes Image Builder], the official tool from the Kubernetes project for building cloud-optimized images. You can refer to the https://image-builder.sigs.k8s.io/[official documentation] for more details on creating custom images.

NOTE: Alternatively, AWS public images with the format `amazon-eks-node-<k8s-version>-v<date>` are also valid, and meet the requirements to deploy _Stratio KEOS_ on EKS.
+
The currently recommended operating system for this provider is Ubuntu 22.04.

* CloudFormation
+
WARNING: If you haven’t created the CloudFormation stack or manually created the IAM prerequisites in the account, you must set the `spec.security.aws.create_iam` parameter to _true_ (default is _false_).

=== GKE

* Permissions
+
In GKE, the service account used to provision the clusters must have the following sets of permissions.
+
** xref:attachment$stratio-gcp-permissions.list[Download GCP permissions].
** xref:attachment$stratio-gke-permissions.list[Download GKE permissions].

* Certified operating systems
+
For GKE, the default OS is Container-Optimized OS (COS), and no specific image needs to be specified.

* Enable the "Google Kubernetes Engine API" for GKE.
* Bastion.
+
Deployment of _Stratio KEOS_ in GKE must be performed through a bastion that enables communication with the cluster. A bastion must be created in the same network as the cluster.

=== Unmanaged Azure

* Permissions
+
To provision in unmanaged Azure, you need an account with all the required permissions, just like in other supported providers. You must also define:
+
** A role for the cluster _workers_ in `spec.security.nodes_identity`.
** A role for the _control-plane_ in `spec.security.control_plane_identity`.
+
For subscription-level permissions, the recommendation is:
+
** xref:attachment$stratio-azure-role.json[Download deployment user permissions for Azure].
** xref:attachment$stratio-azure-nodes-role.json[Download _workers_ permissions for Azure].
** xref:attachment$stratio-azure-cp-role.json[Download _control-plane_ permissions for Azure].
+
For resource group-level permissions, the recommendation is:
+
** xref:attachment$stratio-azure-role-rg.json[Download deployment user permissions for Azure].
** xref:attachment$stratio-azure-nodes-role-rg.json[Download _workers_ permissions for Azure].
** xref:attachment$stratio-azure-cp-role-rg.json[Download _control-plane_ permissions for Azure].
** xref:attachment$stratio-azure-acr.json[Download permissions for deployment user,_ workers_, and _control-plane_ for Azure].
** Additionally, assign these permissions at the resource group level:
*** Deployment user: `Acrpull` on `/subscriptions/<subscription_id>/resourceGroups/<resource_group>/providers/Microsoft.ContainerRegistry/registries/<acr_name>`
*** _Control-plane_: `Acrpull` on `/subscriptions/<subscription_id>/resourceGroups/<resource_group>/providers/Microsoft.ContainerRegistry/registries/<acr_name>`
*** _Workers_: `Acrpull` on `/subscriptions/<subscription_id>/resourceGroups/<resource_group>/providers/Microsoft.ContainerRegistry/registries/<acr_name>`
+
* Certified operating systems
+
To ensure compatibility between the _control-plane_ and _worker_ nodes in unmanaged Azure environments, properly configured OS images must be used. It is recommended to generate them using the https://github.com/kubernetes-sigs/image-builder[Kubernetes Image Builder], the official tool from the Kubernetes project for creating cloud-optimized images. Refer to the https://image-builder.sigs.k8s.io/[official Image Builder documentation] to learn how to build custom images.
+
The recommended OS is Ubuntu 22.04, which is set by default in the Azure controller.

=== Image considerations

Regarding the _control-plane_, in EKS and GKE, it is not possible to specify an image, but in unmanaged Azure, it is.

For _worker_ nodes, specifying an image in unmanaged Azure is optional (if not specified, the controller assigns one provided by the cloud provider).

When creating the image for the cluster, consider the OS requirements of applications (systemd units, DaemonSets, etc.) and the Kubernetes version to be used.

==== Elasticsearch

To support Elasticsearch deployments, the operating system must include the `max_map_count = 262144` parameter in _sysctl_ as specified in its https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html[official documentation].

Amazon Linux 2 images *used by EKS* already include this parameter/value.

== Cluster descriptor

To specify the cluster particulars, the _KeosCluster_ resource is used in a manifest file. The header of this descriptor is the same as any Kubernetes resource:t:

[source,yaml]
----
apiVersion: installer.stratio.com/v1beta1
kind: KeosCluster
metadata:
spec:
----

=== _metadata_

The _metadata_ of the _KeosCluster_ resource comprises the following fields:

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_name_
|Name of the cluster.
|my-cluster
|No
|===

=== _spec_

The _spec_ field of the _KeosCluster_ resource includes these parameters:

[cols="1,1,4,2,1,1"]
|===
^|Name ^|Type ^|Description ^|Example ^|Optional ^|Default

|<<control_plane, _control++_++plane_>>
|Object
|Configuration for the Kubernetes _control-plane_.
|See <<descriptor_example, example descriptor>>
|No
|-

|<<credentials, _credentials_>>
|Object
|Cloud provider credentials used during provisioning.
|See <<descriptor_example, example descriptor>>
|Not required on first run.
|-

|<<deploy_autoscaler, _deploy++_++autoscaler_>>
|Boolean
|Whether to deploy the cluster‑autoscaler in the cluster.
|See <<descriptor_example, example descriptor>>
|Yes
|_true_.

|<<dns, dns>>
|Object
|External DNS configuration for _Stratio KEOS_.
|See <<descriptor_example, example descriptor>>
|Yes
|_manage++_++zone_ default is _true_.

|_docker++_++registries_
|Array
|List of Docker registries accessible from nodes.
|See <<descriptor_example, example descriptor>>
|No
|-

|_external++_++domain_
|String
|External domain accessible outside the cluster.
|See <<descriptor_example, example descriptor>>
|No
|-

|_helm++_++repository_
|Object
|Helm repository to install Stratio charts.
|See <<descriptor_example, example descriptor>>
|No
|-

|_infra++_++provider_
|String
|Name of the cloud provider (AWS, GCP, or Azure).
|aws
|No
|-

|_k8s++_++version_
|String
|Kubernetes version for the cluster. Must be compatible with the cloud provider and _Stratio KEOS_. Note: EKS ignores the patch version.
|v1.26.8
|No
|-

|<<keos, _keos_>>
|Object
|Parameters for installing _Stratio KEOS_.
|See <<descriptor_example, example descriptor>>
|No
|-

|<<networks, _networks_>>
|Object
|Identifiers of pre‑created infrastructure.
|See <<descriptor_example, example descriptor>>
|Sí
|-

|_region_
|String
|Cloud provider region used for provisioning.
|eu-west-1
|No
|-

|<<security, _security_>>
|Object
|Identity and access control configuration, provider‑specific.
|See <<descriptor_example, example descriptor>>
|Azure (No) AWS (Sí) GCP (Sí)
|-

|_storageclass_
|Object
|Default _StorageClass_ configuration for the cluster.
|See <<descriptor_example, example descriptor>>
|Sí
|-

|<<worker_nodes, _worker++_++nodes_>>
|Array
|Worker node group configurations.
|See <<descriptor_example, example descriptor>>
|No
|-
|===

=== Credentials

On the first run, cloud provider credentials for provisioning must be specified here.

These secrets are encrypted with a passphrase provided during provisioning in the _secrets.yml_ file, and the credentials section is removed from the descriptor. For subsequent runs, the passphrase is requested to decrypt the secrets file and retrieve the credentials.

The following credentials fields are considered provisioning secrets:

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_aws_
|Credentials for AWS access.
|See <<descriptor_example, example descriptor>>
|No

|_azure_
|Credentials for Azure access.
|See <<descriptor_example, example descriptor>>
|Not

|_gke_
|Credentials for GKE access.
|See <<descriptor_example, example descriptor>>
|No

|_github++_++token_
|GitHub token. It can be a fine‑grained or classic token, and no special permissions are needed. To generate one: 'Settings' → 'Developer settings' → 'Personal access tokens'.
|_github++_++pat++_++11APW_
|Yes

|_docker++_++registries_
|Docker registries accessible by the nodes. Authentication is not needed on EKS, as it uses user credentials automatically.
|See <<descriptor_example, example descriptor>>
|Yes, for unauthenticated registries.

|_helm++_++repository_
|Helm repository for Stratio charts. Authentication is optional if the repository is public.
|See <<descriptor_example, example descriptor>>
|Yes, for unauthenticated repositories.
|===

=== Credentials for registries and repositories

Credentials must be provided for Docker registries and Helm repositories that require authentication.

==== Docker registry credentials

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_url_
|URL of the Docker registry requiring authentication.
|registry.example.com/org/repo
|No

|_user_
|Username for the Docker registry.
|user
|No

|_pass_
|Password for the Docker registry.
|password
|No
|===

==== Helm repository credentials

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_url_
|URL of the Helm repository requiring authentication.
|https://charts.example.com
|No

|_user_
|Username for the Helm repository.
|user
|No

|_pass_
|Password for the Helm repository.
|password
|No
|===

NOTE: Any change in _spec.credentials_ must include all necessary credentials in the descriptor and delete the previous _secrets.yml_ file.

=== Security

The 'security' section centralizes identity and access control settings for cluster resources, adapted to each cloud provider. It allows specifying identities for both _control-plane_ and nodes, and includes AWS and GCP-specific options.

[cols="1,4,2,1,1"]
|===
^|Name ^|Description ^|Example ^|Optional ^|Provider

|_control++_++plane++_++identity_
|Identity (role, service account, etc.) used by the cluster _control‑plane_.
|/subscriptions/6e2a38cd-../stratio-control-plane
|No
|Azure

|_nodes++_++identity_
|Identity used by _worker_ nodes (role, service account, etc.). +
In GKE, this is the default node service account.
|/subscriptions/6e2a38cd-../stratio-nodes/gke-node-sa@my-project-id.iam.gserviceaccount.com
|No/Yes
|Azure/GCP

|_aws.create++_++iam_
|Whether to create IAM resources specific to the cluster during provisioning.
|false
|Yes (default: _false_)
|AWS

|_gcp.scopes_
|List of scopes available to the node service account, controlling access to GCP services.
a|

[source,yaml]
----
scopes:
  - https://www.googleapis.com/auth/userinfo.email
  - https://www.googleapis.com/auth/cloud-platform
----

|Yes
|GCP
|===

=== Docker repositories

You must specify which Docker registries will be used during installation. This section allows configuring the registry URL, type, and whether authentication is required.

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

| _auth++_++required_
| Indicates if authentication is required.
| _false_
| No.

| _type_
| Docker registry type.
| acr, ecr, gar, gcr, generic
| No

| _url_
| Registry URL.
| AABBCC.dkr.ecr.eu-west-1.amazonaws.com/keos
| No

| _keos++_++registry_
| Indicates if this registry is used for _Stratio KEOS_ images.
| _true_
| No (at least one must be marked _true_).
|===

=== Helm repository

As a prerequisite, you must indicate the Helm repository from which the _Cluster Operator_ chart can be retrieved. This section allows specifying the repository URL, type, and whether it's authenticated.

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

| _auth++_++required_
| Indicates if the repository is authenticated.
| _false_
| Yes. Default: _false_.

| _url_
| Repository URL.
| *OCI registries*: oci://stratioregistry.azurecr.io/helm-repository-example +
*HTTPS registries*: https://[IP]:8080
| No

| _type_
| Repository type.
| generic or ecr.
| Yes. Default: generic.
|===

NOTE: OCI registries (providers such as ECR, GAR, or ACR) are never authenticated via the repo settings. Authentication is handled via provisioning credentials. Please refer to the _Stratio KEOS_ documentation for supported registries in your version.

=== Networks

As previously mentioned, the installer supports using pre‑created cloud provider network elements (e.g., by a network security team), enabling optimal architecture choices.

Both the VPC and subnets must already exist. Subnets may be public or private, but public subnets must include a NAT gateway and an Internet Gateway in the same VPC. If both types are indicated, worker nodes are deployed into private subnets.

_Stratio KEOS_ does not manage the lifecycle of pre‑created resources.

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_vpc++_++id_
|VPC ID.
|vpc-0264503b8761ff69f
|Yes

|_subnets_
|Array of subnet IDs.
a|

[source,yaml]
----
- subnet_id: subnet-0df...
- subnet_id: subnet-887...
----

|Yes
|===

=== _control-plane_

This section specifies _control-plane_ particulars.

[cols="^1,4,3,^1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_aws_
|Specific settings for EKS logging (API Server, audit, authenticator, controller++_++manager_, and/or _scheduler_).
a|

[source,yaml]
----
logging:
  api_server: true
----

|Yes

|_gcp_
|GKE _control‑plane_ specific settings (_private++_++cluster_, _master++_++authorized++_++networks++_++config_, _ip++_++allocation++_++policy_, _monitoring++_++config_, and _logging++_++config_).
a|

[source,yaml]
----
cluster_network:
  private_cluster:
----
+
[source,yaml]
----
master_authorized_networks_config:
----
+
[source,yaml]
----
ip_allocation_policy:
----
+
[source,yaml]
----
monitoring_config:
----
+
[source,yaml]
----
logging_config:
----

|Refer to the Quick Start guide for details.

|_managed_
|Indicates if the cloud provider manages the _control-plane_.
|true
|No
|===

=== _worker_ nodes

This section defines the _worker_node groups and their characteristics.

EKS must support the images used. See the https://docs.aws.amazon.com/es_es/eks/latest/userguide/eks-optimized-ami.html[AMI creation for customized EKS].

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_name_
|Group name, used as instance name prefix.
|eks-prod-gpu
|No

|_quantity_
|Number of nodes in the group. A multiple of 3 is recommended to avoid AZ imbalance.
|15
|No

|_size_
|Instance type.
|t3.medium
|No

|_max++_++size_/_min++_++size_
|Maximum and minimum autoscaling range.
|6/18.
|Yes

|_az_
|Single AZ for the group (overrides _zone++_++distribution_).
|eu-east-1a
|Yes

|_zone++_++distribution_
|Whether nodes are evenly distributed across zones (default) or not.
|unbalanced
|Yes

|_node++_++image_
|Instance image for _worker_ nodes.
|ami-0de933c15c9b49fb5
|Yes

|_labels_
|Kubernetes labels for _worker_ nodes.
a|

[source,yaml]
----
labels:
  disktype: standard
  gpus: true
----

|Yes

|_root++_++volume_
|Volume specifics like size, type, and encryption.
a|

[source,yaml]
----
root_volume:
  size: 50
  type: gp3
  encrypted: true
----

|Yes

|_ssh++_++key_
|Public SSH key for node access; should already exist in AWS. It's recommended not to add any SSH keys to nodes.
|prod-key
|Yes
|===

NOTE: Setting _min++_++size_ to zero is supported, allowing autoscaler to scale down to zero nodes, which can save costs, particularly for groups with zero deployed instances when not needed.

=== _Stratio KEOS_

Installation parameters for _keos-installer_ are provided here.

[cols="1,4,2,1"]
|===
^|Name ^|Description ^|Example ^|Optional

|_flavour_
|Installation flavor indicating cluster size and resiliency. Default is "production".
|development
|Yes

|_version_
|_keos-installer_ version.
|1.0.0
|No
|===

=== Descriptor example

Two descriptor examples are provided demonstrating _Stratio Cloud Provisioner_ capabilities for supported cloud providers.

==== EKS

This example includes:

* AWS cluster with managed _control-plane_ (EKS).
* Kubernetes 1.26.x (EKS ignores patch version).
* Use of ECR as Docker registry (no credentials needed).
* Use of VPC and custom subnets (pre-created; optional).
* Default _StorageClass_ defined (optional).
* Enabled API Server logs in EKS.
* Worker node groups with multiple configurations:
** Different instance types.
** With SSH key.
** Kubernetes labels.
** Autoscaling ranges.
** Fixed AZ.
** Custom root volume.
** Spot instances.
** AZ distribution: balanced or unbalanced.

[source,yaml]
----
apiVersion: installer.stratio.com/v1beta1
kind: KeosCluster
metadata:
  name: eks-prod
spec:
  infra_provider: aws
  credentials:
    aws:
      region: eu-west-1
      access_key: AKIAT4..
      account_id: '3683675..'
      secret_key: wq3/Vsc..
    github_token: github_pat_11APW..
  k8s_version: v1.26.7
  region: eu-west-1
  external_domain: domain.ext
  networks:
    vpc_id: vpc-02698..
    subnets:
      - subnet_id: subnet-0416d..
      - subnet_id: subnet-0b2f8..
      - subnet_id: subnet-0df75..
  docker_registries:
    - url: AABBCC.dkr.ecr.eu-west-1.amazonaws.com/keos
      auth_required: false
      type: ecr
      keos_registry: true
  helm_repository:
    auth_required: false
    url: http://charts.stratio.com
  storageclass:
    parameters:
      type: gp3
      fsType: ext4
      encrypted: "true"
      labels: "owner=stratio"
  dns:
    manage_zone: false
  deploy_autoscaler: false
  keos:
    flavour: production
    version: 1.0.4
  security:
    aws:
      create_iam: false
  control_plane:
    aws:
      logging:
        api_server: true
    managed: true
  worker_nodes:
    - name: eks-prod-xlarge
      quantity: 6
      max_size: 18
      min_size: 6
      size: m6i.xlarge
      labels:
        disktype: standard
      root_volume:
        size: 50
        type: gp3
        encrypted: true
      ssh_key: stg-key
    - name: eks-prod-medium-spot
      quantity: 4
      zone_distribution: unbalanced
      size: t3.medium
      spot: true
      labels:
        disktype: standard
    - name: eks-prod-medium-az
      quantity: 3
      size: t3.medium
      az: eu-west-1c
----

==== GKE

This example includes:

* GCP cluster with managed _control-plane_.
* Kubernetes 1.28.x.
* Use of Docker registry of type GAR.
* Use of Helm repository of type GAR.
* _nodes++_++identity_ (default node service account configurable only at create time).
* scopes (list of access scopes for service account).
* No DNS zone control (enabled by default).
* Default _StorageClass_ definition (optional).
* _Control-plane_ settings configurable only at creation time:
** _cluster++_++network_
*** _private++_++cluster_
**** _enable++_++private++_++endpoint_
**** _enable++_++private++_++nodes_
**** _control++_++plane++_++cidr++_++block_
** ip++_++allocation++_++policy
*** cluster++_++ipv4++_++cidr++_++block
*** services++_++ipv4++_++cidr++_++block
*** cluster++_++secondary++_++range++_++name
*** services++_++secondary++_++range++_++name
** _monitoring++_++config_
*** _enable++_++managed++_++prometheus_
** _master++_++authorized++_++networks++_++config_
*** _cidr++_++blocks_
*** _gcp++_++public++_++cidrs++_++access++_++enabled_
** _logging++_++config_
*** _system++_++components_
*** _workloads_
* _Worker_ node groups with multiple configurations:
** Different instance types.
** No specific image (uses cloud provider default).
** Kubernetes labels.
** Autoscaling ranges.
** Fixed AZ.
** Custom root volume.

[source,yaml]
----
apiVersion: installer.stratio.com/v1beta1
kind: KeosCluster
metadata:
  name: gcp-prod
spec:
  infra_provider: gcp
  credentials:
    gcp:
      private_key_id: "efdf19f5605a.."
      private_key: "-----BEGIN PRIVATE KEY-----\nMIIEvw.."
      client_email: keos@stratio.com
      project_id: gcp-prod
      region: europe-west4
      client_id: "6767910929.."
  security:
    nodes_identity: "gke-node-sa@my-project-id.iam.gserviceaccount.com"
    gcp:
      scopes:
        - "https://www.googleapis.com/auth/cloud-platform"
        - "https://www.googleapis.com/auth/userinfo.email"
  k8s_version: v1.28.15
  region: europe-west4
  docker_registries:
      - url: europe-docker.pkg.dev/stratio-keos/keos
        auth_required: false
        type: gar
        keos_registry: true
  helm_repository:
      auth_required: false
      url: http://charts.stratio.com
      type: gar
  dns:
    manage_zone: false
  external_domain: domain.ext
  networks:
    vpc_id: gcp-prod-vpc
    subnets:
      - subnet_id: gcp-prod-subnet
  storageclass:
    parameters:
      type: pd-standard
      fsType: ext4
      replication-type: none
      labels: "owner=stratio"
  keos:
    flavour: production
    version: 1.1.3
  control_plane:
    managed: true
    gcp:
      cluster_network:
        private_cluster:
          enable_private_endpoint: true
          enable_private_nodes: true
          control_plane_cidr_block: 172.16.16.0/28
      ip_allocation_policy:
        cluster_ipv4_cidr_block: 172.16.0.0/16
        services_ipv4_cidr_block: 172.17.0.0/20
        cluster_secondary_range_name: "gkepods-europ-west1"
        services_secondary_range_name: "gkeservices-europe-west1"
      monitoring_config:
        enable_managed_prometheus: false
      master_authorized_networks_config:
        cidr_blocks:
          - cidr_block: 192.168.100.0/24
            display_name: Office Network
          - cidr_block: 172.16.0.0/20
            display_name: VPC Network
        gcp_public_cidrs_access_enabled: false
      logging_config:
        system_components: false
        workloads: false
  worker_nodes:
    - name: gcp-prod-xlarge
      quantity: 6
      max_size: 18
      min_size: 6
      size: c2d-highcpu-8
      labels:
        disktype: standard
      root_volume:
        size: 50
        type: pd-standard
        encrypted: true
        encryption_key: projects/gcp-prod/locations/europe-west4/keyRings/keos-keyring/cryptoKeys/keos-key
    - name: gcp-prod-medium-az
      quantity: 3
      size: c2d-highcpu-4
      az: europe-west4-a
---
apiVersion: installer.stratio.com/v1beta1
kind: ClusterConfig
metadata:
    name: gcp-prod-config
spec:
    private_registry: true
    private_helm_repo: true
    cluster_operator_version: 0.3.4
    cluster_operator_image_version: 0.3.4
----

==== Unmanaged Azure

This example includes:

* Azure cluster with unmanaged _control-plane_.
* Use of ACR as Docker registry (no credentials needed).
* Use of a specific CIDR block for pods.
* Default _StorageClass_ defined (optional).
* _Control-plane_ VMs with:
** High availability (3 instances).
** Specific instance type.
** No specific image (optional).
** Custom root volume.
* _Worker_ node group with:
** Specific image (optional).
+
NOTE: Component versions in the image must align with the specified Kubernetes version.
** Kubernetes labels.
** Autoscaling ranges.
** Custom root volume.

[source,yaml]
----
apiVersion: installer.stratio.com/v1beta1
kind: KeosCluster
metadata:
  name: azure-prod
spec:
  infra_provider: azure
  credentials:
    azure:
      client_id: ee435ab0..
      client_secret: lSF8Q~n..
      subscription_id: '6e2a38cd-e..'
      tenant_id: '9c2f8eb6-5..'
  k8s_version: v1.26.8
  region: westeurope
  docker_registries:
    - url: eosregistry.azurecr.io/keos
      auth_required: false
      type: acr
      keos_registry: true
  helm_repository:
    auth_required: false
    url: http://charts.stratio.com
  storageclass:
    parameters:
      type: StandardSSD_LRS
      fsType: ext4
      tags: "owner=stratio"
  external_domain: domain.ext
  dns:
    manage_zone: false
  keos:
    flavour: production
    version: 1.0.4
  security:
    control_plane_identity: "/subscriptions/6e2a38cd-../stratio-control-plane"
    nodes_identity: "/subscriptions/6e2a38cd-../stratio-nodes"
  control_plane:
    managed: false
    size: Standard_D8_v3
    node_image: "/subscriptions/6e2a38cd-../images/capi-ubuntu-2204-1687262553"
    root_volume:
      size: 100
      type: StandardSSD_LRS
  worker_nodes:
    - name: azure-prod-std
      quantity: 3
      max_size: 18
      min_size: 3
      size: Standard_D8_v3
      node_image: "/subscriptions/6e2a38cd-../images/capi-ubuntu-2204-1687262553"
      labels:
        backup: "false"
      root_volume:
        size: 100
        type: StandardSSD_LRS
----

== Cluster creation

_Stratio Cloud Provisioner_ is a tool that automates provisioning of required cloud resources to create a Kubernetes cluster based on the provided <<cluster_descriptor, descriptor>>.

The binary currently supports the following options:

- `--avoid-creation`: only creates the _local_ cluster, not the _worker_ cluster.
- `--build-stratio-image`: builds the _Stratio Cloud Provisioner_ image locally instead of downloading it. Intended for development.
- `--delete-previous`: removes local cluster container if it already exists.
- `-d, --descriptor <string>`: specifies the descriptor file name (default: _cluster.yaml_).
- `-h, --help`: shows command help.
- `--keep-mgmt`: retains management cluster in kind (only for *non‑production environments*).
- `--local-stratio-image-version <string>`: overrides local installer image version when using `use-local-stratio-image`.
- `-n, --name <string>`: cluster name; overrides `KIND_CLUSTER_NAME`, config (default: _kind_).
- `--retain`: preserves nodes for debugging if cluster creation fails.
- `--use-local-stratio-image`: uses local installer image without building or downloading.
- `--validate-only`: validates the descriptor without creating a cluster.
- `-p, --vault-password <string>`: sets Vault password for secret encryption.

To create a cluster, a simple command is sufficient (see quick‑start guide for provider-specific details):

[source,bash]
-----
sudo ./cloud-provisioner create cluster --name stratio-pre --descriptor cluster-gcp.yaml
Vault Password:
Creating temporary cluster "stratio-pre" ...
 ✓ Ensuring node image (kindest/node:v1.27.0) 🖼
 ✓ Building Stratio image (stratio-capi-image:v1.27.0) 📸
 ✓ Preparing nodes 📦
 ✓ Writing configuration 📜
 ✓ Starting control-plane 🕹️
 ✓ Installing CNI 🔌
 ✓ Installing StorageClass 💾
 ✓ Installing CAPx 🎖️
 ✓ Generating secrets file 📝🗝️
 ✓ Installing keos cluster operator 💻
 ✓ Creating the workload cluster 💥
 ✓ Saving the workload cluster kubeconfig 📝
 ✓ Installing Calico in workload cluster 🔌
 ✓ Installing CSI in workload cluster 💾
 ✓ Creating Kubernetes RBAC for internal loadbalancing 🔐
 ✓ Preparing nodes in workload cluster 📦
 ✓ Installing StorageClass in workload cluster 💾
 ✓ Enabling workload clusters self-healing 🏥
 ✓ Installing CAPx in workload cluster 🎖️
 ✓ Configuring Network Policy Engine in workload cluster 🚧
 ✓ Installing cluster-autoscaler in workload cluster 🗚
 ✓ Installing keos cluster operator in workload cluster 💻
 ✓ Creating cloud-provisioner Objects backup 🗄️
 ✓ Moving the management role 🗝️
 ✓ Executing post-install steps 🎖️
 ✓ Generating the KEOS descriptor 📝

The cluster has been installed successfully. Please refer to the documents below on how to proceed:
1. Post-installation _Stratio Cloud Provisioner_ documentation.
2. _Stratio KEOS_ documentation.
-----

Once completed, you will have the necessary files (_keos.yaml_ and _secrets.yml_) to install _Stratio KEOS_.

NOTE: Since the descriptor file (_keos.yaml_) is regenerated on each run, the previous one is backed up locally with the corresponding timestamp (e.g., _keos.yaml.2023-07-05@11:19:17~_).

=== Load balancer

Due to a bug in certain controllers (fixed in master branches but not yet released), the load balancer created for GCP and Azure clusters with unmanaged _control-planes_ is created with a TCP-based health check.

This may lead to request issues if a _control-plane_ node fails—since the load balancer may route traffic to a node that responds on port but cannot process requests.

To avoid this, modify the load balancer health check to use HTTPS and the path _/readyz_, keeping the same port: 443 for GCP and 6443 for Azure.

== Deployment of _aws-load-balancer-controller_ (EKS only)

In EKS clusters, you can deploy the _aws-load-balancer-controller_, which manages Elastic Load Balancer creation for objects like _Ingress_ and _Service_ of type _LoadBalancer_.

Since this is not enabled by default, you must set `spec.eks_lb_controller` to "true" in the _ClusterConfig_ resource of the cluster descriptor.

To authorize the controller, use IAM roles for service accounts, which involves creating corresponding IAM objects as follows:

* Set the necessary environment variables:
+
[source,shell]
----
export AWS_ACCOUNT_ID=<account_id>
export AWS_REGION=<aws_region>
export AWS_VPC_ID=<vpc_id>
export AWS_EKS_CLUSTER_NAME=<aws_eks_cluster_name>
export AWS_EKS_OIDC_ID=$(aws eks describe-cluster --region ${AWS_REGION} --name ${AWS_EKS_CLUSTER_NAME} --query 'cluster.identity.oidc.issuer' --output text | awk -F'/' '{print $NF}')
export AWS_IAM_POLICY_NAME="${AWS_EKS_CLUSTER_NAME}-lb-controller-manager"
export AWS_IAM_ROLE_NAME="${AWS_EKS_CLUSTER_NAME}-lb-controller-manager"
----

* https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create.html[Create the IAM role] used by the _aws‑load‑balancer‑controller_ service account with the trust policy:
+
[source,console]
----
$ cat << EOF > trustpolicy.json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Federated": "arn:aws:iam::${AWS_ACCOUNT_ID}:oidc-provider/oidc.eks.${AWS_REGION}.amazonaws.com/id/${AWS_EKS_OIDC_ID}"
            },
            "Action": "sts:AssumeRoleWithWebIdentity",
            "Condition": {
                "StringEquals": {
                    "oidc.eks.${AWS_REGION}.amazonaws.com/id/${AWS_EKS_OIDC_ID}:sub": "system:serviceaccount:kube-system:aws-load-balancer-controller",
                    "oidc.eks.${AWS_REGION}.amazonaws.com/id/${AWS_EKS_OIDC_ID}:aud": "sts.amazonaws.com"
                }
            }
        }
    ]
}
EOF
$ aws iam create-role --role-name ${AWS_IAM_ROLE_NAME} --assume-role-policy-document file://trustpolicy.json
----

* https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_create.html[Create the IAM policy] with strictly required permissions:
+
[source,console]
----
$ cat << EOF > policy.json
{
	"Statement": [
		{
			"Action": [
        			"ec2:DescribeAvailabilityZones",
				"ec2:DescribeInstances",
				"ec2:DescribeSecurityGroups",
				"ec2:DescribeSubnets",
				"elasticloadbalancing:DescribeListeners",
				"elasticloadbalancing:DescribeLoadBalancers",
				"elasticloadbalancing:DescribeLoadBalancerAttributes",
				"elasticloadbalancing:DescribeRules",
				"elasticloadbalancing:DescribeTags",
				"elasticloadbalancing:DescribeTargetGroups",
				"elasticloadbalancing:DescribeTargetGroupAttributes",
				"elasticloadbalancing:DescribeTargetHealth",
        "shield:GetSubscriptionState"
			],
			"Effect": "Allow",
			"Resource": "*"
		},
		{
			"Action": [
				"ec2:AuthorizeSecurityGroupIngress",
				"ec2:CreateSecurityGroup",
        			"ec2:CreateTags",
				"ec2:DeleteSecurityGroup",
				"ec2:RevokeSecurityGroupIngress"
			],
			"Effect": "Allow",
			"Resource": [
				"arn:aws:ec2:${AWS_REGION}:${AWS_ACCOUNT_ID}:vpc/${AWS_VPC_ID}",
				"arn:aws:ec2:${AWS_REGION}:${AWS_ACCOUNT_ID}:security-group/*"
			]
		},
		{
			"Action": [
				"elasticloadbalancing:AddTags",
				"elasticloadbalancing:CreateListener",
				"elasticloadbalancing:CreateLoadBalancer",
				"elasticloadbalancing:CreateTargetGroup",
				"elasticloadbalancing:DeleteLoadBalancer",
				"elasticloadbalancing:DeleteTargetGroup",
				"elasticloadbalancing:DeregisterTargets",
				"elasticloadbalancing:ModifyLoadBalancerAttributes",
				"elasticloadbalancing:ModifyTargetGroup",
				"elasticloadbalancing:RegisterTargets"
			],
			"Effect": "Allow",
			"Resource": "*",
			"Condition": {
				"StringEquals": {
					"aws:ResourceTag/elbv2.k8s.aws/cluster": "${AWS_EKS_CLUSTER_NAME}"
				}
			}
		}
	],
	"Version": "2012-10-17"
}
EOF
$ aws iam create-policy --policy-name ${AWS_IAM_POLICY_NAME} --policy-document file://policy.json
----

* https://docs.aws.amazon.com/es_es/IAM/latest/UserGuide/access_policies_manage-attach-detach.html[Attach the policy] to the created role:
+
[source,console]
----
$ aws iam attach-role-policy --role-name ${AWS_IAM_ROLE_NAME} --policy-arn arn:aws:iam::${AWS_ACCOUNT_ID}:policy/${AWS_IAM_POLICY_NAME}
----

* Restart the controller (_aws-load-balancer-controller_):
+
[source,console]
----
$ kubectl -n kube-system rollout restart deployment aws-load-balancer-controller
----
