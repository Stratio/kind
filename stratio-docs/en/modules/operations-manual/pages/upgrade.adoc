= Version upgrade

== Description

The `upgrade-provisioner.py` script automates Kubernetes cluster upgrades in the following environments:

* *EKS* on AWS (managed)
* *Azure VMs* (unmanaged)

It allows you to upgrade the Kubernetes cluster version from the version installed by `cloud-provisioner 0.7.X` to the one provided by `cloud-provisioner 0.8.0`. To ensure a reproducible runtime environment, the Docker image `cloud-provisioner-upgrade:0.17.0-0.8.0` has been created, which includes the upgrade script and all necessary dependencies.

=== What Gets Updated

==== Common Components (All Platforms)

* *cluster-operator:* `0.6.0`
* *cert-manager:* `v1.19.1`
* *flux2:* `2.17.2`
* *tigera-operator:* `v3.30.2`
* *cluster-autoscaler:* `9.52.1`

==== Cluster API Core

* *cluster-api (CAPI):* `v1.10.8`
* *bootstrap-kubeadm:* `v1.10.8`
* *control-plane-kubeadm:* `v1.10.8`

==== Infrastructure Providers (Platform-Specific)

* *CAPA (AWS):* `v2.9.2`
* *CAPZ (Azure):* `v1.21.1`
* *CAPG (GCP):* `1.6.1-0.4.0` _(not yet tested)_

==== Platform-specific charts

*EKS (if installed):*

* *aws-load-balancer-controller:* `1.14.1`

*Azure VMs:*

* *azuredisk-csi-driver:* `1.33.5`
* *azurefile-csi-driver:* `1.34.1`
* *cloud-provider-azure:* `1.34.2`

== Requirements

=== Technical requirements

* Docker installed on your system
* `kubeconfig` file with access to the cluster
* `secrets.yml` file (Ansible Vault) used during cluster creation
* Local directory for backups (will be mounted into the container)

=== Functional requirements

Before executing the upgrade, verify that your cluster meets the following conditions:

==== KeosCluster Ready

[source,bash]
----
kubectl get keosclusters.installer.stratio.com -A
----

*Expected output:*

* `READY = true`
* `PHASE = Provisioned`

==== Nodes Healthy

[source,bash]
----
kubectl get nodes
----

*Expected:* all nodes with `STATUS = Ready`

==== Machines Running

[source,bash]
----
kubectl get machines -A
----

*Expected:* all with `PHASE = Running`

==== MachineDeployments Healthy

[source,bash]
----
kubectl get machinedeployments -A
----

*Expected:*

* `READY = REPLICAS`
* `UNAVAILABLE = 0`

==== Cluster API Pods Healthy

[source,bash]
----
kubectl get pods -n capi-system
kubectl get pods -n capa-system   # or capz-system / capg-system
----

*Expected:* all pods in `Running` state and logs without errors

==== Cluster-Operator Ready

[source,bash]
----
kubectl get helmrelease cluster-operator -n kube-system
----

*Expected:* `Ready = True`

=== Permissions

It is essential to xref:operations-manual:installation.adoc[review the documentation] to ensure that no additional permissions are required in the cluster.

== Preparation

Create a local backup directory:

[source,bash]
----
mkdir -p /local/path/backup
----

NOTE: This directory must be mounted inside the container at `/upgrade/backup`

== Required structure

Ensure that the working directory includes:

* `upgrade-provisioner.py`: main script
* `templates/`: Jinja2 templates
* `files/`: additional files (configurations, Helm, etc.)
* `requirements.txt`: required dependencies
* `secrets.yml`: cluster credentials
* `.kube/`: directory with the `kubeconfig` file

== Important notes

=== Registry configuration

[%header,cols="1,2"]
|===
| Scenario | Action required

| Without `--private` flag
| Clusterctl uses `registry.k8s.io` images

| Private registry only
| *MUST* use `--private` flag
|===

[WARNING]
====
If your cluster can only access a private registry, the `--private` flag is *mandatory*.
====

== Using the upgrade script

=== Syntax

Inside the container, run:

[source,bash]
----
python3 upgrade-provisioner.py -p <vault-password>
----

To check available flags and their usage:

[source,bash]
----
python3 upgrade-provisioner.py --help
----

Main options:

[%header,cols="1,2,1,1"]
|===
| Flag | Description | Default value | Mandatory

| `-p`, `--vault-password`
| Vault password required to decrypt secrets
|
| Yes

| `-y`, `--yes`
| Do not require confirmation between tasks (automatic mode)
| False
| No

| `-k`, `--kubeconfig`
| Specify the kubectl configuration file to use
| ~/.kube/config
| No

| `-s`, `--secrets`
| Encrypted secrets file
| secrets.yml
| No

| `--disable-backup`
| Disable backup before upgrading (enabled by default)
| False
| No

| `--disable-prepare-capsule`
| Disable environment preparation for the upgrade process
| False
| No

| `--skip-k8s-intermediate-version`
| Skip upgrading workers to the intermediate Kubernetes version. This is only compatible with EKS environments
| False
| No

| `--private`
| Treat the Docker registry and Helm repository as private
| False
| No
|===

=== Running the upgrade container

[source,bash]
----
docker run \
  --name cloud-provisioner-upgrade-0.8.0 \
  --net host \
  -it \
  -v /local/path/secrets.yml:/upgrade/secrets.yml \
  -v /local/path/.kube/config:/upgrade/.kube/config \
  -v /local/path/backup:/upgrade/backup \
  cloud-provisioner-upgrade:0.17.0-0.8.0
----

=== Using the version upgrade script

==== Syntax

[source,bash]
----
python3 upgrade-provisioner.py [OPTIONS]
----

Key options:

[%header,cols="1,2,1,1"]
|===
| Flag | Description | Default value | Mandatory

| `-p`, `--vault-password`
| Specify the Vault password needed to decrypt secrets
|
| Yes

| `--private`
| Treat the Docker registry and Helm repository as private
| False
| No

|===

== Upgrade process overview

The script executes the following workflow:

. *Validation*
** Validates `kubeconfig` and secrets
** Configures cloud credentials

. *Pre-upgrade*
** *Scales cluster-autoscaler to 0* (prevents node scaling during upgrade)

. *Backup*
** CAPX components (using `clusterctl move`)
** Capsule webhook configurations

. *Capsule preparation*
** *Modifies Capsule webhooks* to exclude critical namespaces from validation/mutation
** Ensures tenant isolation doesn't block component upgrades

. *Chart updates*
** Updates base charts (cert-manager, flux2, tigera-operator, etc.)
** Updates provider-specific charts (aws-load-balancer-controller, Azure CSI drivers)
** *Restores Capsule webhooks* to original configuration

. *Cluster-Operator preparation*
** *Suspends cluster-operator HelmRelease*
** *Stops keoscluster-controller deployment*
** *Disables keoscluster validating/mutating webhooks*
** Updates ClusterConfig with new component versions

. *CAPI upgrade*
+
[source,bash]
----
clusterctl upgrade apply \
  --core cluster-api:v1.10.8 \
  --infrastructure <provider>:<version> \
  --wait-providers
----

. *Post-upgrade*
** *Restores keoscluster webhooks*
** *Starts keoscluster-controller deployment*
** *Unsuspends cluster-operator HelmRelease*
** Waits for cluster-operator to be ready
** Waits for KeosCluster ready state
** *Restores cluster-autoscaler replicas to 2*

== Monitoring during upgrade

=== Watch autoscaler

[source,bash]
----
watch -n2 kubectl -n kube-system get deploy cluster-autoscaler-clusterapi-cluster-autoscaler
----

=== Monitor critical pods

[source,bash]
----
watch -n2 'kubectl get pods -A | grep -E "cluster-operator|capi|cap.|autoscaler|tigera"'
----

=== Track HelmReleases

[source,bash]
----
watch -n2 kubectl get helmreleases -A
----

== Final verification

=== Verify container images

[source,bash]
----
kubectl get pods -A -o json \
| jq -r '
  .items[]
  | (
      [.spec.containers[]?.image] +
      [.spec.initContainers[]?.image]
    )
  | .[]
' \
| sort -u
----

*Expected versions:*

* CAPI → `v1.10.8`
* CAPA → `v2.9.2`
* CAPG → `1.6.1-0.4.0`
* CAPZ → `v1.21.1`

=== Verify chart versions

[source,bash]
----
kubectl get hr -A -o json \
| jq -r '
  .items[]
  | "\(.metadata.namespace)/\(.metadata.name) -> \(.spec.chart.spec.chart)@\(.spec.chart.spec.version)"
' \
| sort -u
----

=== Final state check

[source,bash]
----
kubectl get keoscluster -A
kubectl get machines -A
kubectl get machinedeployments -A
kubectl get nodes
----

*Expected state:*

* ✅ All resources: `Ready`
* ✅ All machines: `Running`
* ✅ No `Unavailable` replicas